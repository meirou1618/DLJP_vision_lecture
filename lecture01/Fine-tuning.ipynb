{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Fine-tuning.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"dDxysntJbreq"},"source":["# ファインチューニング 演習\n","\n","本日の演習ではファインチューニングについて取り扱う。\n","\n","ファインチューニングは、特定の（大規模）データセットで学習した学習済みモデルを初期値として、他の学習データを用いて学習させることである。\n","\n","一般に目的のデータ数が少ないとき、大きいモデルを一から学習して精度を高めるのは困難である。そのような状況においてファインチューニングを用いることで、大規模データセットで事前学習された特徴量を初期値として使うことが出来るので、精度を高めることが可能となる。\n","\n","現に、今日のCIFAR10等のベンチマークの最高精度は、「より大規模なデータセットを用いた事前学習」＋「CIFAR10等によるファインチューニング」という形で達成されている。\n","\n"]},{"cell_type":"markdown","metadata":{"id":"4x-gEZzfhVhB"},"source":["本日の演習では、「ImageNetで事前学習されたモデル」と「CIFAR10（の一部）」を用いてファインチューニングを実装し、事前学習しないモデルを用いた場合と比較することでファインチューニングの効果を確認する。"]},{"cell_type":"code","metadata":{"id":"nBBIHMk3Ii6r"},"source":["import torch\n","from torch import nn, optim\n","from torchvision import datasets, transforms, models\n","import numpy as np\n","import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xkGSQ9_rh0mz"},"source":["## 前処理・データローダーの実装\n","\n","pytorchではImageNetで事前学習されたモデル（学習済みモデル）をダウンロードして用いることが出来る。\n","\n","事前学習されたモデルを用いる場合、元データと同じ前処理を用いる必要があるので、ここで定義する。\n","\n","また、CIFARデータローダーも定義する。ファインチューニングの効果をより明確に示すために、ここではCIFAR10の訓練データ数をデフォルトの50000から、10分の1の5000に減らしている。"]},{"cell_type":"code","metadata":{"id":"1ZYrnWIUKQnm"},"source":["# 学習済みモデルでは、前処理に以下の平均分散を用いた正規化を行う\n","normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                 std=[0.229, 0.224, 0.225])\n","\n","# データセットの定義に用いるtransformを定義する\n","# Big Transfer[1] を参考にサイズを128にリサイズする（もともとは32）\n","transform_valid = transforms.Compose([\n","                    transforms.Resize(128),\n","                    transforms.ToTensor(),\n","                    normalize\n","                ])\n","\n","# 訓練データではデータAugmentaionも加える\n","transform_train = transforms.Compose([\n","                    transforms.Resize(160),\n","                    transforms.RandomCrop(128),\n","                    transforms.RandomHorizontalFlip(p=0.5),\n","                    transforms.ToTensor(),\n","                    normalize\n","                ])\n","\n","\n","batch_size = 128\n","\n","# CIFAR10の50000枚の訓練データを分割し、5000枚のみを用いる\n","train_dataset = datasets.CIFAR10('./data/cifar10', train=True, download=True, transform=transform_train)\n","train_dataset, _ = torch.utils.data.random_split(train_dataset, [5000, 45000])\n","\n","dataloader_train = torch.utils.data.DataLoader(\n","    train_dataset,\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","\n","valid_dataset = datasets.CIFAR10('./data/cifar10', train=False, download=True, transform=transform_train)\n","valid_dataset, _ = torch.utils.data.random_split(valid_dataset, [3000, 7000])\n","\n","dataloader_valid = torch.utils.data.DataLoader(\n","    valid_dataset,\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","\n","# [1] Kolesnikov, Alexander, et al. \"Big transfer (bit): General visual representation learning.\" In Proc. of ECCV. 2020."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-E27BAmukuPZ"},"source":["## ファインチューニングを行わない場合\n","\n","まずは、ベースラインとして、ファインチューニングを行わない場合の精度を確認する。\n","\n","モデルはResNet18を用いているが、別のモデルを用いてもよい。"]},{"cell_type":"code","metadata":{"id":"n3i-WEFNb4AY"},"source":["n_epochs = 10\n","lr = 0.001\n","device = 'cuda'\n","\n","# pytorchではtorchvision.modelsから有名なモデルを呼び出してそのまま用いることが出来る\n","resnet18 = models.resnet18()\n","\n","# デフォルトのresnet18は1000クラス分類用なので、全結合層を10クラス用に変更する\n","resnet18.fc = nn.Linear(512,10)\n","\n","resnet18.to(device)\n","optimizer = optim.Adam(resnet18.parameters(), lr=lr)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ppS3F8ypb8gM"},"source":["for epoch in range(n_epochs):\n","    losses_train = []\n","    losses_valid = []\n","\n","    resnet18.train()\n","    n_train = 0\n","    acc_train = 0\n","    for x, t in tqdm.notebook.tqdm(dataloader_train):\n","        n_train += t.size()[0]\n","\n","        resnet18.zero_grad()  # 勾配の初期化\n","\n","        x = x.to(device)  # テンソルをGPUに移動\n","\n","        t_hot = torch.eye(10)[t]  # 正解ラベルをone-hot vector化\n","\n","        t = t.to(device)\n","        t_hot = t_hot.to(device)  # 正解ラベルとone-hot vectorをそれぞれGPUに移動\n","\n","        y = resnet18(x)  # 順伝播\n","\n","        loss = -(t_hot*torch.log_softmax(y, dim=-1)).sum(axis=1).mean()  # 誤差(クロスエントロピー誤差関数)の計算\n","\n","        loss.backward()  # 誤差の逆伝播\n","\n","        optimizer.step()  # パラメータの更新\n","\n","        pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n","\n","        acc_train += (pred == t).float().sum().item()\n","        losses_train.append(loss.tolist())\n","\n","    resnet18.eval()\n","    n_val = 0\n","    acc_val = 0\n","    for x, t in dataloader_valid:\n","        n_val += t.size()[0]\n","\n","        x = x.to(device)  # テンソルをGPUに移動\n","\n","        t_hot = torch.eye(10)[t]  # 正解ラベルをone-hot vector化\n","\n","        t = t.to(device)\n","        t_hot = t_hot.to(device)  # 正解ラベルとone-hot vectorをそれぞれGPUに移動\n","\n","        y = resnet18(x)  # 順伝播\n","\n","        loss = -(t_hot*torch.log_softmax(y, dim=-1)).sum(axis=1).mean()  # 誤差(クロスエントロピー誤差関数)の計算\n","\n","        pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n","\n","        acc_val += (pred == t).float().sum().item()\n","        losses_valid.append(loss.tolist())\n","\n","    print('EPOCH: {}, Train [Loss: {:.3f}, Accuracy: {:.3f}], Valid [Loss: {:.3f}, Accuracy: {:.3f}]'.format(\n","        epoch,\n","        np.mean(losses_train),\n","        acc_train/n_train,\n","        np.mean(losses_valid),\n","        acc_val/n_val\n","    ))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F9_AO3Ltb_t1"},"source":["## 学習済みモデルの使用\n","\n","次は学習済みモデルを用いる。\n","\n","pytorchではtorchvisionのデフォルトのモデルに対して、ImageNetの学習済みモデルを用いることが出来る。\n","\n","ImageNetは1000クラス約130万枚のデータセットで、CIFAR10よりもはるかに大規模なデータセットである。"]},{"cell_type":"code","metadata":{"id":"glmYoR3pNH36"},"source":["n_epochs = 10\n","lr = 0.001\n","device = 'cuda'\n","\n","# pretrained = Trueと入れるとImageNetで事前学習された重みがセットされる\n","resnet18_pretrained = models.resnet18(pretrained=True)\n","\n","resnet18_pretrained.fc = nn.Linear(512,10)\n","\n","resnet18_pretrained.to(device)\n","optimizer = optim.Adam(resnet18_pretrained.parameters(), lr=lr)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rzqcBbWBNW9z"},"source":["for epoch in range(n_epochs):\n","    losses_train = []\n","    losses_valid = []\n","\n","    resnet18_pretrained.train()\n","    n_train = 0\n","    acc_train = 0\n","    for x, t in tqdm.notebook.tqdm(dataloader_train):\n","        n_train += t.size()[0]\n","\n","        resnet18_pretrained.zero_grad()  # 勾配の初期化\n","\n","        x = x.to(device)  # テンソルをGPUに移動\n","\n","        t_hot = torch.eye(10)[t]  # 正解ラベルをone-hot vector化\n","\n","        t = t.to(device)\n","        t_hot = t_hot.to(device)  # 正解ラベルとone-hot vectorをそれぞれGPUに移動\n","\n","        y = resnet18_pretrained(x)  # 順伝播\n","\n","        loss = -(t_hot*torch.log_softmax(y, dim=-1)).sum(axis=1).mean()  # 誤差(クロスエントロピー誤差関数)の計算\n","\n","        loss.backward()  # 誤差の逆伝播\n","\n","        optimizer.step()  # パラメータの更新\n","\n","        pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n","\n","        acc_train += (pred == t).float().sum().item()\n","        losses_train.append(loss.tolist())\n","\n","    resnet18_pretrained.eval()\n","    n_val = 0\n","    acc_val = 0\n","    for x, t in dataloader_valid:\n","        n_val += t.size()[0]\n","\n","        x = x.to(device)  # テンソルをGPUに移動\n","\n","        t_hot = torch.eye(10)[t]  # 正解ラベルをone-hot vector化\n","\n","        t = t.to(device)\n","        t_hot = t_hot.to(device)  # 正解ラベルとone-hot vectorをそれぞれGPUに移動\n","\n","        y = resnet18_pretrained(x)  # 順伝播\n","\n","        loss = -(t_hot*torch.log_softmax(y, dim=-1)).sum(axis=1).mean()  # 誤差(クロスエントロピー誤差関数)の計算\n","\n","        pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n","\n","        acc_val += (pred == t).float().sum().item()\n","        losses_valid.append(loss.tolist())\n","\n","    print('EPOCH: {}, Train [Loss: {:.3f}, Accuracy: {:.3f}], Valid [Loss: {:.3f}, Accuracy: {:.3f}]'.format(\n","        epoch,\n","        np.mean(losses_train),\n","        acc_train/n_train,\n","        np.mean(losses_valid),\n","        acc_val/n_val\n","    ))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-dtBYZWWnhnu"},"source":["デフォルトの設定では、10エポック学習したとき、ファインチューニング無しのモデルでは50%程度の精度しか達成できていない。\n","\n","一方でファインチューニングを用いた場合、80%程度の精度を達成している。\n","\n","80%という精度は、10分の1の量のCIFAR10及びResNet18という条件では、しっかり学習を回しても簡単には達成できない精度なので、この精度を数分で達成できるファインチューニングの有効性が示されている。"]},{"cell_type":"markdown","metadata":{"id":"x84dcVAGpZHy"},"source":["## torchvision.modelの紹介\n","torchvision.modelには、今回用いたResNet18以外にも様々なモデルが用意されているので紹介する\n","詳細は (https://pytorch.org/vision/stable/models.html) を参考にしていただきたい"]},{"cell_type":"code","metadata":{"id":"rRixY7qOpq0T"},"source":["# torchvisionには例として以下のモデルが実装されており（他にもたくさんある）\n","# 全てのモデルに対してImageNet Pretrainを用いることが出来る\n","resnet18 = models.resnet18()\n","alexnet = models.alexnet()\n","vgg16 = models.vgg16()\n","squeezenet = models.squeezenet1_0()\n","densenet = models.densenet161()\n","inception = models.inception_v3()\n","googlenet = models.googlenet()\n","shufflenet = models.shufflenet_v2_x1_0()\n","mobilenet_v2 = models.mobilenet_v2()\n","mobilenet_v3_large = models.mobilenet_v3_large()\n","mobilenet_v3_small = models.mobilenet_v3_small()\n","resnext50_32x4d = models.resnext50_32x4d()\n","wide_resnet50_2 = models.wide_resnet50_2()\n","mnasnet = models.mnasnet1_0()"],"execution_count":null,"outputs":[]}]}