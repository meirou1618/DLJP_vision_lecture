{"cells":[{"cell_type":"markdown","metadata":{"id":"JmBi3Gs1DmAb"},"source":["# 動作確認用のファイル"]},{"cell_type":"markdown","metadata":{"id":"N0uz7ym4DmAh"},"source":["## 次のセルを実行して動くかどうか確認してください。\n","### 最低限のGPU環境があるかどうかを確認するためのものです。講義で使用する資料が動くことを保証するものではありません。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":651},"id":"ixuHuEtKDmAm","outputId":"bdcd2b92-1eaa-4105-eab5-4effaec7dc60"},"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:183: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:206: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:233: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"]},{"output_type":"stream","name":"stdout","text":["0/50000\n","10000/50000\n","20000/50000\n","30000/50000\n","40000/50000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:266: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"]},{"output_type":"stream","name":"stdout","text":["0/50000\n","10000/50000\n","20000/50000\n","30000/50000\n","40000/50000\n","EPOCH: 0, Train [Loss: 1.451, Accuracy: 0.486], Valid [Loss: 1.090, Accuracy: 0.608]\n","EPOCH: 1, Train [Loss: 0.886, Accuracy: 0.687], Valid [Loss: 0.847, Accuracy: 0.698]\n","EPOCH: 2, Train [Loss: 0.702, Accuracy: 0.754], Valid [Loss: 0.778, Accuracy: 0.735]\n","EPOCH: 3, Train [Loss: 0.597, Accuracy: 0.793], Valid [Loss: 0.810, Accuracy: 0.725]\n","EPOCH: 4, Train [Loss: 0.510, Accuracy: 0.822], Valid [Loss: 0.816, Accuracy: 0.734]\n"]},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fbf2a8d5150>"]},"metadata":{},"execution_count":2},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.autograd as autograd\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms, models\n","\n","\n","import matplotlib.pyplot as plt\n","\n","from sklearn.utils import shuffle\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","\n","# 既存のGCNクラスは存在しないので、自作する.\n","class gcn():\n","    def __init__(self):\n","        pass\n","\n","    def __call__(self, x):\n","        mean = torch.mean(x)\n","        std = torch.std(x)\n","        return (x - mean)/(std + 10**(-6))  # 0除算を防ぐ\n","\n","\n","def deprocess(x):\n","    _min = np.min(x)\n","    _max = np.max(x)\n","    _x = (x - _min)/(_max - _min)\n","    return _x\n","\n","# ZCA白色化の実装\n","class ZCAWhitening():\n","    def __init__(self, epsilon=1e-4, device=\"cuda\"):  # 計算が重いのでGPUを用いる\n","        self.epsilon = epsilon\n","        self.device = device\n","\n","    def fit(self, images):  # 変換行列と平均をデータから計算\n","        x = images[0][0].reshape(1, -1)\n","        self.mean = torch.zeros([1, x.size()[1]]).to(self.device)\n","        con_matrix = torch.zeros([x.size()[1], x.size()[1]]).to(self.device)\n","        for i in range(len(images)):  # 各データについての平均を取る\n","            x = images[i][0].reshape(1, -1).to(self.device)\n","            self.mean += x / len(images)\n","            con_matrix += torch.mm(x.t(), x) / len(images)\n","            if i % 10000 == 0:\n","                print(\"{0}/{1}\".format(i, len(images)))\n","        con_matrix -= torch.mm(self.mean.t(), self.mean)\n","        E, V = torch.symeig(con_matrix, eigenvectors=True)  # 固有値分解\n","        self.ZCA_matrix = torch.mm(torch.mm(V, torch.diag((E.squeeze()+self.epsilon)**(-0.5))), V.t())\n","        #print(\"completed!\")\n","\n","    def __call__(self, x):\n","        size = x.size()\n","        x = x.reshape(1, -1).to(self.device)\n","        x -= self.mean\n","        #print(x)\n","        x = torch.mm(x, self.ZCA_matrix.t())\n","        #print(x)\n","        x = x.reshape(tuple(size))\n","        x = x.to(\"cpu\")\n","        return x    \n","\n","class BatchNorm(nn.Module):\n","    def __init__(self, shape, epsilon=np.float32(1e-5)):\n","        super().__init__()\n","        self.gamma = nn.Parameter(torch.tensor(np.ones(shape, dtype='float32')))\n","        self.beta = nn.Parameter(torch.tensor(np.zeros(shape, dtype='float32')))\n","        self.epsilon = epsilon\n","\n","    def forward(self, x):\n","        mean = torch.mean(x, (0, 2, 3), keepdim=True)\n","        std = torch.std(x, (0, 2, 3), keepdim=True)\n","        x_normalized = (x - mean) / (std**2 + self.epsilon)**0.5\n","        return self.gamma * x_normalized + self.beta\n","\n","class Conv(nn.Module):\n","    def __init__(self, filter_shape, function=lambda x: x, stride=(1, 1), padding=0):\n","        super().__init__()\n","        # Heの初期値\n","        fan_in = filter_shape[1] * filter_shape[2] * filter_shape[3]\n","        # filter_shape: (出力チャンネル数)x(入力チャンネル数)x(縦の次元数)x(横の次元数)\n","        fan_out = filter_shape[0] * filter_shape[2] * filter_shape[3]\n","\n","        self.W = nn.Parameter(torch.tensor(rng.normal(\n","                        0,\n","                        np.sqrt(2/fan_in),\n","                        size=filter_shape\n","                    ).astype('float32')))\n","\n","        # バイアスはフィルタごとなので, 出力フィルタ数と同じ次元数\n","        self.b = nn.Parameter(torch.tensor(np.zeros((filter_shape[0]), dtype='float32')))\n","\n","        self.function = function\n","        self.stride = stride\n","        self.padding = padding\n","\n","    def forward(self, x):\n","        u = F.conv2d(x, self.W, bias=self.b, stride=self.stride, padding=self.padding)\n","        return self.function(u)\n","\n","class Pooling(nn.Module):\n","    def __init__(self, ksize=(2, 2), stride=(2, 2), padding=0):\n","        super().__init__()\n","        self.ksize = ksize\n","        self.stride = stride\n","        self.padding = padding\n","\n","    def forward(self, x):\n","        return F.avg_pool2d(x, kernel_size=self.ksize, stride=self.stride, padding=self.padding)\n","\n","\n","class Flatten(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, x):\n","        return x.view(x.size()[0], -1)\n","\n","class Dense(nn.Module):\n","    def __init__(self, in_dim, out_dim, function=lambda x: x):\n","        super().__init__()\n","        # He Initialization\n","        # in_dim: 入力の次元数、out_dim: 出力の次元数\n","               \n","        self.W = nn.Parameter(torch.tensor(rng.normal(\n","                        0,\n","                        np.sqrt(2/in_dim),\n","                        size=(in_dim, out_dim)\n","                    ).astype('float32')))\n","\n","        self.b = nn.Parameter(torch.tensor(np.zeros([out_dim]).astype('float32')))\n","        self.function = function\n","\n","    def forward(self, x):\n","        return self.function(torch.matmul(x, self.W) + self.b)\n","\n","class Activation(nn.Module):\n","    def __init__(self, function=lambda x: x):\n","        super().__init__()\n","        self.function = function\n","\n","    def __call__(self, x):\n","        return self.function(x)\n","        \n","        \n","# torch.log(0)によるnanを防ぐ\n","def torch_log(x):\n","    return torch.log(torch.clamp(x, min=1e-10))\n","\n","\n","rng = np.random.RandomState(1234)\n","random_state = 42\n","\n","batch_size = 1  # 可視化の際に扱いやすくするために1とする。\n","\n","dataloader_train = torch.utils.data.DataLoader(\n","    datasets.CIFAR10('./data/cifar10', train=True, download=True, transform=transforms.ToTensor()),\n","    batch_size=batch_size,\n","    shuffle=False\n",")\n","\n","\n","transform = transforms.Compose([transforms.RandomHorizontalFlip(p=1.0),  # horizontally flipping\n","                                transforms.ToTensor()])\n","\n","dataloader_train_flip = torch.utils.data.DataLoader(\n","    datasets.CIFAR10('./data/cifar10', train=True, transform=transform),\n","    batch_size=batch_size,\n","    shuffle=False\n",")\n","\n","# fig = plt.figure(figsize=(9, 15))\n","# fig.subplots_adjust(left=0, right=1, bottom=0, top=0.5, hspace=0.05,\n","#                    wspace=0.05)\n","\n","i = 0\n","for x, _ in dataloader_train_flip:\n","    x = np.transpose(torch.squeeze(x).numpy(), (1, 2, 0))\n","    ax = fig.add_subplot(9, 9, i + 1, xticks=[], yticks=[])\n","#    ax.imshow(x)\n","    i += 1\n","    if i >= 81:\n","        break\n","\n","\n","transform = transforms.Compose([transforms.RandomCrop(32, padding=(4, 4, 4, 4), padding_mode='constant'),  # random cropoing\n","                                transforms.ToTensor()])\n","\n","dataloader_train_crop = torch.utils.data.DataLoader(\n","    datasets.CIFAR10('./data/cifar10', train=True, transform=transform),\n","    batch_size=batch_size,\n","    shuffle=False\n",")\n","\n","# fig = plt.figure(figsize=(9, 15))\n","# fig.subplots_adjust(left=0, right=1, bottom=0, top=0.5, hspace=0.05,\n","#                    wspace=0.05)\n","\n","i = 0\n","for x, _ in dataloader_train_crop:\n","    x = np.transpose(torch.squeeze(x).numpy(), (1, 2, 0))\n","    ax = fig.add_subplot(9, 9, i + 1, xticks=[], yticks=[])\n","#    ax.imshow(x)\n","    i += 1\n","    if i >= 81:\n","        break\n","\n","\n","\n","\n","\n","GCN = gcn()\n","transform_GCN = transforms.Compose([transforms.ToTensor(),\n","                                    GCN])\n","\n","dataloader_train_gcn = torch.utils.data.DataLoader(\n","    datasets.CIFAR10('./data/cifar10', train=True, transform=transform_GCN),\n","    batch_size=batch_size,\n","    shuffle=False\n",")\n","\n","# fig = plt.figure(figsize=(9, 15))\n","# fig.subplots_adjust(left=0, right=1, bottom=0, top=0.5, hspace=0.05,\n","#                    wspace=0.05)\n","\n","i = 0\n","for x, _ in dataloader_train_gcn:\n","    x = np.transpose(torch.squeeze(x).numpy(), (1, 2, 0))\n","    ax = fig.add_subplot(9, 9, i + 1, xticks=[], yticks=[])\n","#    ax.imshow(deprocess(x))\n","    i += 1\n","    if i >= 81:\n","        break\n","\n","\n","\n","\n","\n","\n","\n","\n","zca = ZCAWhitening()\n","images = datasets.CIFAR10('./data/cifar10', train=True, transform=transforms.ToTensor())\n","zca.fit(images)\n","\n","transform_zca = transforms.Compose([transforms.ToTensor(),\n","                                    zca])\n","\n","dataloader_train_zca = torch.utils.data.DataLoader(\n","    datasets.CIFAR10('./data/cifar10', train=True, transform=transform_zca),\n","    batch_size=batch_size,\n","    shuffle=False\n",")\n","\n","# fig = plt.figure(figsize=(9, 15))\n","# fig.subplots_adjust(left=0, right=1, bottom=0, top=0.5, hspace=0.05,\n","#                    wspace=0.05)\n","\n","i = 0\n","for x, _ in dataloader_train_zca:\n","    x = np.transpose(torch.squeeze(x).numpy(), (1, 2, 0))\n","    ax = fig.add_subplot(9, 9, i + 1, xticks=[], yticks=[])\n","#    ax.imshow(deprocess(x))\n","    i += 1\n","    if i >= 81:\n","        break\n","\n","conv_net = nn.Sequential(\n","    Conv((32, 3, 3, 3)),     # 32x32x3 -> 30x30x32\n","    BatchNorm((32, 30, 30)),\n","    Activation(F.relu),\n","    Pooling((2, 2)),                  # 30x30x32 -> 15x15x32\n","    Conv((64, 32, 3, 3)),     # 15x15x32 -> 13x13x64\n","    BatchNorm((64, 13, 13)),\n","    Activation(F.relu),\n","    Pooling((2, 2)),                 # 13x13x64 -> 6x6x64\n","    Conv((128, 64, 3, 3)),           # 6x6x64 -> 4x4x128\n","    BatchNorm((128, 4, 4)),\n","    Activation(F.relu),\n","    Pooling((2, 2)),                 # 4x4x128 -> 2x2x128\n","    Flatten(),\n","    Dense(2*2*128, 256, F.relu),\n","    Dense(256, 10)\n",")\n","\n","batch_size = 100\n","n_epochs = 5\n","lr = 0.01\n","device = 'cuda'\n","\n","conv_net.to(device)\n","optimizer = optim.Adam(conv_net.parameters(), lr=lr)\n","\n","\n","trainval_dataset = datasets.CIFAR10('./data/cifar10', train=True, transform=transforms.ToTensor())\n","\n","#zcaを定義\n","zca = ZCAWhitening()\n","zca.fit(trainval_dataset)\n","\n","# 前処理を定義\n","transform = transforms.Compose([transforms.ToTensor(),\n","                                zca])\n","\n","trainval_dataset = datasets.CIFAR10('./data/cifar10', train=True, transform=transform)\n","\n","# trainとvalidに分割\n","train_dataset, val_dataset = torch.utils.data.random_split(trainval_dataset, [len(trainval_dataset)-10000, 10000])\n","\n","dataloader_train = torch.utils.data.DataLoader(\n","    train_dataset,\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","\n","dataloader_valid = torch.utils.data.DataLoader(\n","    val_dataset,\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","\n","\n","for epoch in range(n_epochs):\n","    losses_train = []\n","    losses_valid = []\n","\n","    conv_net.train()\n","    n_train = 0\n","    acc_train = 0\n","    for x, t in dataloader_train:\n","        n_train += t.size()[0]\n","\n","        conv_net.zero_grad()  # 勾配の初期化\n","\n","        x = x.to(device)  # テンソルをGPUに移動\n","\n","        t_hot = torch.eye(10)[t]  # 正解ラベルをone-hot vector化\n","\n","        t = t.to(device)\n","        t_hot = t_hot.to(device)  # 正解ラベルとone-hot vectorをそれぞれGPUに移動\n","\n","        y = conv_net.forward(x)  # 順伝播\n","\n","        loss = -(t_hot*torch.log_softmax(y, dim=-1)).sum(axis=1).mean()  # 誤差(クロスエントロピー誤差関数)の計算\n","\n","        loss.backward()  # 誤差の逆伝播\n","\n","        optimizer.step()  # パラメータの更新\n","\n","        pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n","\n","        acc_train += (pred == t).float().sum().item()\n","        losses_train.append(loss.tolist())\n","\n","    conv_net.eval()\n","    n_val = 0\n","    acc_val = 0\n","    for x, t in dataloader_valid:\n","        n_val += t.size()[0]\n","\n","        x = x.to(device)  # テンソルをGPUに移動\n","\n","        t_hot = torch.eye(10)[t]  # 正解ラベルをone-hot vector化\n","\n","        t = t.to(device)\n","        t_hot = t_hot.to(device)  # 正解ラベルとone-hot vectorをそれぞれGPUに移動\n","\n","        y = conv_net.forward(x)  # 順伝播\n","\n","        loss = -(t_hot*torch.log_softmax(y, dim=-1)).sum(axis=1).mean()  # 誤差(クロスエントロピー誤差関数)の計算\n","\n","        pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n","\n","        acc_val += (pred == t).float().sum().item()\n","        losses_valid.append(loss.tolist())\n","\n","    print('EPOCH: {}, Train [Loss: {:.3f}, Accuracy: {:.3f}], Valid [Loss: {:.3f}, Accuracy: {:.3f}]'.format(\n","        epoch,\n","        np.mean(losses_train),\n","        acc_train/n_train,\n","        np.mean(losses_valid),\n","        acc_val/n_val\n","    ))\n","\n","\n","trainval = datasets.CIFAR10('./data/cifar10')\n","image_id = 919  # 表示させる画像を選択\n","sample_image = trainval[image_id][0]\n","plt.imshow(sample_image)\n","\n","print(\"最後の画像が表示されれば、10分以内に終われば最低限の演習環境として問題ないです。そうでない場合やもっと早く行いたいと思う方は、案内を参考に別の環境の用意をご検討ください。\")\n"]}],"metadata":{"accelerator":"GPU","anaconda-cloud":{},"colab":{"collapsed_sections":[],"name":"【受講前】演習環境チェック用.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":0}